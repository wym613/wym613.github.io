{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 128\n",
    "        self.dir_data='data/'\n",
    "        self.num_of_classes,self.dict =create_dic(self.dir_data)\n",
    "        self.image_size = 28\n",
    "        self.validate_data = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mini_classes.txt','w') as f:\n",
    "    for file in sorted(os.listdir('data/')):\n",
    "        if file.endswith(\".npy\"):\n",
    "            print(file.split(\".\")[0], file = f)\n",
    "f = open(\"mini_classes.txt\",\"r\")\n",
    "# And for reading use\n",
    "classes = f.readlines()\n",
    "f.close()\n",
    "classes = [c.replace('\\n','').replace(' ','_') for c in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ambulance',\n",
       " 'apple',\n",
       " 'axe',\n",
       " 'basketball',\n",
       " 'bicycle',\n",
       " 'bird',\n",
       " 'butterfly',\n",
       " 'car',\n",
       " 'carrot',\n",
       " 'cat',\n",
       " 'chair',\n",
       " 'clock',\n",
       " 'cookie',\n",
       " 'cup',\n",
       " 'donut',\n",
       " 'envelope',\n",
       " 'flower',\n",
       " 'key',\n",
       " 'knife',\n",
       " 'lightning',\n",
       " 'pencil',\n",
       " 'pizza',\n",
       " 'rainbow',\n",
       " 'snake',\n",
       " 'spider',\n",
       " 'star',\n",
       " 'tractor',\n",
       " 'tree',\n",
       " 'whale',\n",
       " 'windmill']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dic(dir_data):\n",
    "    dict={}\n",
    "    i=0\n",
    "    for file in sorted(os.listdir(dir_data)):\n",
    "        if file.endswith(\".npy\"):\n",
    "            str=file.split(\".\")\n",
    "            dict[i]=str[0]\n",
    "            i=i+1\n",
    "    return i,dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(cnn):\n",
    "    dir_data='data/'\n",
    "    num_of_classess,dict=create_dic(dir_data)\n",
    "    data_l=np.zeros((1))\n",
    "    data_d=np.zeros((1,cnn.image_size*cnn.image_size))\n",
    "    index=0\n",
    "    class_names = []\n",
    "    for file in sorted(os.listdir(dir_data)):\n",
    "        if file.endswith(\".npy\"):\n",
    "            print(data_l.shape,data_d.shape,\"cur label num!\",index,file)\n",
    "            curr_data=np.load(dir_data+file)\n",
    "\n",
    "            #change to white background\n",
    "            curr_data=255-curr_data;\n",
    "            data_d=np.concatenate((data_d,curr_data))\n",
    "            data_l=np.concatenate((data_l,np.ones(curr_data.shape[0])*index))\n",
    "            index=index+1\n",
    "            class_names.append(file.split('.')[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    data_l=np.expand_dims(data_l,1)\n",
    "    data_all=np.concatenate((data_d,data_l),axis=1)\n",
    "    data_all=np.random.permutation(data_all)\n",
    "\n",
    "    x_data=data_all[:,0:-1]\n",
    "    y_data=data_all[:,-1]\n",
    "    num_img=x_data.shape[0]\n",
    "    data_img=np.reshape(x_data,[num_img,cnn.image_size,cnn.image_size])\n",
    "\n",
    "\n",
    "    data_train=data_img[cnn.validate_data:,:,:]\n",
    "    data_train=np.expand_dims(data_train,3)\n",
    "\n",
    "    labels_train=y_data[cnn.validate_data:]\n",
    "    data_test=data_img[:cnn.validate_data:,:,:]\n",
    "    data_test=np.expand_dims(data_test,3)\n",
    "\n",
    "    labels_test=y_data[:cnn.validate_data]\n",
    "\n",
    "\n",
    "    return data_train,labels_train,data_test,labels_test,class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,) (1, 784) cur label num! 0 ambulance.npy\n",
      "(148005,) (148005, 784) cur label num! 1 apple.npy\n",
      "(292727,) (292727, 784) cur label num! 2 axe.npy\n",
      "(416849,) (416849, 784) cur label num! 3 basketball.npy\n",
      "(550642,) (550642, 784) cur label num! 4 bicycle.npy\n",
      "(677169,) (677169, 784) cur label num! 5 bird.npy\n",
      "(810741,) (810741, 784) cur label num! 6 butterfly.npy\n",
      "(928740,) (928740, 784) cur label num! 7 car.npy\n",
      "(1111504,) (1111504, 784) cur label num! 8 carrot.npy\n",
      "(1243963,) (1243963, 784) cur label num! 9 cat.npy\n",
      "(1367165,) (1367165, 784) cur label num! 10 chair.npy\n",
      "(1589871,) (1589871, 784) cur label num! 11 clock.npy\n",
      "(1710407,) (1710407, 784) cur label num! 12 cookie.npy\n",
      "(1841760,) (1841760, 784) cur label num! 13 cup.npy\n",
      "(1972481,) (1972481, 784) cur label num! 14 donut.npy\n",
      "(2113232,) (2113232, 784) cur label num! 15 envelope.npy\n",
      "(2248095,) (2248095, 784) cur label num! 16 flower.npy\n",
      "(2392913,) (2392913, 784) cur label num! 17 key.npy\n",
      "(2553878,) (2553878, 784) cur label num! 18 knife.npy\n",
      "(2726534,) (2726534, 784) cur label num! 19 lightning.npy\n",
      "(2878094,) (2878094, 784) cur label num! 20 pencil.npy\n",
      "(3000095,) (3000095, 784) cur label num! 21 pizza.npy\n",
      "(3130466,) (3130466, 784) cur label num! 22 rainbow.npy\n",
      "(3257311,) (3257311, 784) cur label num! 23 snake.npy\n",
      "(3379584,) (3379584, 784) cur label num! 24 spider.npy\n",
      "(3589031,) (3589031, 784) cur label num! 25 star.npy\n",
      "(3726650,) (3726650, 784) cur label num! 26 tractor.npy\n",
      "(3843327,) (3843327, 784) cur label num! 27 tree.npy\n",
      "(3988048,) (3988048, 784) cur label num! 28 whale.npy\n",
      "(4104550,) (4104550, 784) cur label num! 29 windmill.npy\n"
     ]
    }
   ],
   "source": [
    "quick_draw_cnn=cnn()\n",
    "x_train, y_train, x_test, y_test, class_names = load_data(quick_draw_cnn)\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_train))\n",
    "plt.imshow(x_train[idx].reshape(28,28)) \n",
    "print(class_names[int(y_train[idx].item())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], quick_draw_cnn.image_size, quick_draw_cnn.image_size, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], quick_draw_cnn.image_size, quick_draw_cnn.image_size, 1).astype('float32')\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# Convert class vectors to class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               16500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 95,230\n",
      "Trainable params: 95,230\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=[5,5], padding='same',input_shape=x_train.shape[1:], activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=[5,5],padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=[5,5],padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(layers.Convolution2D(filters=32, kernel_size=[5,5],padding='same', activation= 'relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=500, activation='relu'))\n",
    "model.add(layers.Dense(units=num_classes, activation='softmax')) \n",
    "# Train model\n",
    "adam = tf.train.AdamOptimizer()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['top_k_categorical_accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 231202 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "231202/231202 [==============================] - 224s 969us/step - loss: 0.0628 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0342 - val_top_k_categorical_accuracy: 1.0000\n",
      "10000/10000 [==============================] - 2s 182us/step\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model.fit(x = x_train, y = y_train, validation_data=(x_test, y_test), batch_size=quick_draw_cnn.batch_size, epochs=1)\n",
    "acc = model.evaluate(x_test, y_test,batch_size=quick_draw_cnn.batch_size)\n",
    "print('Test accuracy:', acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['butterfly', 'cat']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAEjxJREFUeJzt3Xt0VeWZBvDnJQmoBOUWMAaQSwkWUMBmotYuilIVOyhYkRE7DqgVbb3UjtOlwzhLp3UsU4sOdoFLrBSweKFWhI4woIyzhBaBgAgiFx2KgCAkQRFULkne+SOHrgjZ7z45t73D+/zWciWc5+zsz0Medk6+vfcnqgoi8qdF1AMgomiw/EROsfxETrH8RE6x/EROsfxETrH8RE6x/EROsfxETuXncmcd2+dp964FudwlkSvbdhxF1b5aSea5aZVfRIYBmAwgD8BvVHWi9fzuXQuwclHXdHZJRIbyK3Yk/dyUf+wXkTwAUwBcCaAvgDEi0jfVr0dEuZXOe/5yAB+o6lZVPQLgBQAjMjMsIsq2dMpfAqDhzxg7E499hYiMF5EKEamorK5NY3dElEnplL+xXyqccH2wqk5T1TJVLSvqkJfG7ogok9Ip/04ADX971wXArvSGQ0S5kk75VwHoLSI9RKQlgOsBzM/MsIgo21Ke6lPVGhG5E8Ai1E/1TVfVDRkbGRFlVVrz/Kq6AMCCDI2FiHKIp/cSOcXyEznF8hM5xfITOcXyEznF8hM5xfITOcXyEznF8hM5xfITOcXyEznF8hM5xfITOZXTW3fH2Zajn5v53f83OjD79NCpae272+mfmPnsHovNvEB4hyRqOh75iZxi+YmcYvmJnGL5iZxi+YmcYvmJnGL5iZw6aeb5/63SXiN00S8Gm/kZr6w1cz30UfC25pbh9ofkw8vHmXnlA0cCszVlL5rbHqw7ZOYzP+tt5k+sv8TM8/ODl2ibNOAlc9thpx0282z6oi74NQWAg3rUzDvltc7kcLKCR34ip1h+IqdYfiKnWH4ip1h+IqdYfiKnWH4ip9Ka5xeRbQAOAKgFUKOqZZkYVJDyt68LzNqP/NDctm3PKjPf/MhAMx91yVuB2aDT7H2HeWq7fQ4CftXKjIuuXh+YXbhglLnt/hWdzLzbz5abeXddZ+aWx8U+N+OBmy8085vu/S8zn/L8VYFZj98Fn7cBADV/sf9OpZX9d/Lp3K5m/tZA+xyHXMjEST6XqKrdLCKKHf7YT+RUuuVXAItFZLWIjM/EgIgoN9L9sf9iVd0lIp0AvCYim1T1zYZPSPyjMB4AupWcNJcSEDV7aR35VXVX4uNeAHMBlDfynGmqWqaqZUUdeKNJorhIufwi0lpE2hz7HMDlAN7N1MCIKLvS+Tm8M4C5InLs6zynqv+dkVERUdaJquZsZ2UDTtGVi4LnP3fWHDS3v+3b3w/MDvbrbG47Y8pjZt6joNDMo3RUg6+JB4Dv3P7DwKz1ym3mtrWV1WZ+cNTfmPmuofbYHhj8x8Ds4TeuNrftc/caM5eWLe3cmIvf9fdfN7fd36/GzEteFzMvnPe2mZcuD+7dE2etMre1lF+xAxXvHLIHl8CpPiKnWH4ip1h+IqdYfiKnWH4ip1h+Iqdidb7tg7uGmbl1mWXRLHuJ7ThP5YUJW4L7lkdfDsyeO7enuW1+txIznztpkpmnc4vqkstnmvnk/EFmrkft6bib1m4IzEYXvmFuG2bv39rfb+PWjzXzNRM7BIdPpD7V1xQ88hM5xfITOcXyEznF8hM5xfITOcXyEznF8hM5Fat5/nVVZ5l5e2wJzK4uspfYPpmVFHwSHGqdue3Gfyo282wuNT3hvZFmfuYpH5t53af24uYd8uxLxNMR9rpsvK+tmZfevCIwe+UX9jkpI1tn5v+LR34ip1h+IqdYfiKnWH4ip1h+IqdYfiKnWH4ip2I1z1+193Qzb29kQ07bFvLVm+/1/GF+8PrNgVlpbYW57cTLX8j0cJK2puxFM+/x2A/MvPRm+/+td4F1HkB2vx+uOu8dM99sZM/tucDcdmTPJSmM6EQ88hM5xfITOcXyEznF8hM5xfITOcXyEznF8hM5FTrPLyLTAQwHsFdV+yceaw/gRQDdAWwDMFpVjYvKk9P5zE9T3nZy5WAzn1RsL/fcnH3t2aOB2Rcjy81tRxfaS0lHSb601ytACzsvzjs1g6Npmhvav2XmD+Ibgdma7cHL2AMA7KUYkpbMkX8GgONX07gfwBJV7Q1gSeLPRNSMhJZfVd8EsO+4h0cAOLbcykwA9i1ZiCh2Un3P31lVdwNA4mOnzA2JiHIh67/wE5HxIlIhIhWV1bXZ3h0RJSnV8u8RkWIASHzcG/REVZ2mqmWqWlbUIeQXOESUM6mWfz6AY8uQjgUwLzPDIaJcCS2/iDwPYDmAPiKyU0RuATARwGUi8j6AyxJ/JqJmJHSeX1XHBERDMzwWvNR/hpmPb3dVYPa/T51jbrtuwp/N/LyWp5h5lB6p6mPmLZYFr1lQOefcTA8nZ/IO2MemvHZnmHmBRPc283fV3wx5xuHA5PTCLzM7mAA8w4/IKZafyCmWn8gplp/IKZafyCmWn8ipWN26u0u+fTvlTT8rDcx637Xc3Pa+WUPMvPrvBpm5XlcdmL064Lfmtukucz1z/qVm3rPNu4HZqxc8GfLV43tL84LPxX5CyFRfrbE8+ewD9uUoWw7ZS5fvOWzfZn7H7d3NPL/n54HZkkH29xNwWkieHB75iZxi+YmcYvmJnGL5iZxi+YmcYvmJnGL5iZyK1Tx/mK3XPhWYTRlq3+748VeHm3nvZ+07j9fN3BKYjesQfKkxAJQsCL58EwCe7vonMz97oX2JZ/W1/QOzXgVLzW3jrNXxt409Tm3HNmY+eP2owKxw2NZUhtRA8Dw9AOSX2N9PFy0M3n+7vMzM44fhkZ/IKZafyCmWn8gplp/IKZafyCmWn8gplp/IqWY1z2+5o+0OM7/9hilm/o3td5p553XB2dH+Z5vbDmk738y31xw08xYrgq/XB4DK759v5s1V0dv2XHrVefZ9Ehb2C76XwdCf/tTc9qxH7Vu9b/3lRWb+zCj7PgqDY3CneB75iZxi+YmcYvmJnGL5iZxi+YmcYvmJnGL5iZwKnecXkekAhgPYq6r9E489BOBWAJWJp01Q1QXZGmQmfG3+7WZe+mt7XnfL1PLAbNMI+xyCVlJg5v/w4XfNXGs+M/OLBrxv5nH1Se0XZt5i9SZ7+zEDzdxaL6HinsnmttfMu97MCz+01xSIwzx+mGSO/DMADGvk8cdVdWDiv1gXn4hOFFp+VX0TQMg9VYiouUnnPf+dIrJORKaLSLuMjYiIciLV8j8JoBeAgQB2A5gU9EQRGS8iFSJSUVldm+LuiCjTUiq/qu5R1VpVrQPwNIDA34ap6jRVLVPVsqIOeamOk4gyLKXyi0jDJUyvAWBfdkZEsZPMVN/zAIYA6CgiOwE8CGCIiAwEoAC2Abgti2MkoiwILb+qjmnk4WeyMJa0bDhi39v+nJ8YF+QD2H33N838LyOnGqk9jx9m6TvnmHlpi9Vm/vMufzTSwhRGlBuPVl1o5nrYXu+gtN/OlPcddu7FoW5tzbzgc01533HBM/yInGL5iZxi+YmcYvmJnGL5iZxi+YmcOmlu3X3junFmXnRos5mPufW1DI6maTqsDjnzsayvGfcqsKcC4+qlzfYluT1gT8/+Y7fFmRzOV+R/aZ+KXnNq1nadMzzyEznF8hM5xfITOcXyEznF8hM5xfITOcXyEzl10szzf3m4ZVrbDzh1e4ZG0nSdllWZ+UdXFOVoJLnVeY49WZ7fpcTMK2vtZdmB6sDkrUP2PH7++q1m/vmV/UL2HX888hM5xfITOcXyEznF8hM5xfITOcXyEznF8hM5ddLM8w8++wMz3xay/b9uGmHmw86f07QBNfCnQ3VmXrvRXmL7wD+3SXnfUXu4Kvi25K1fXWtuWxNy6+5Zfbqa+ezSIYGZHD5ibqtHKs38kdGzzbw54JGfyCmWn8gplp/IKZafyCmWn8gplp/IKZafyKnQeX4R6QpgFoAzAdQBmKaqk0WkPYAXAXRH/TT6aFX9JHtDtU0sXmLmoy69y8w7jtli5uf+8EeB2RmXfmxu+9Gu9mZeigozH9g97Lr16DxS1cfMl19dGpjJOa3NbQc/u8bMZ2ywl/guWGd/fcuA4QfN/NrCz1L+2nGRzJG/BsC9qvp1ABcCuENE+gK4H8ASVe0NYEniz0TUTISWX1V3q+qaxOcHAGwEUAJgBICZiafNBDAyW4Mkosxr0nt+EekOYBCAFQA6q+puoP4fCACdMj04IsqepMsvIoUA/gDgHlVN+g2PiIwXkQoRqaistu+bRkS5k1T5RaQA9cWfraovJx7eIyLFibwYwN7GtlXVaapapqplRR1CFqQkopwJLb+ICIBnAGxU1ccaRPMBjE18PhbAvMwPj4iyRVTVfoLItwAsBbAe9VN9ADAB9e/75wDoBmA7gOtUdZ/1tcoGnKIrF9mXYWbL2pDLQ2/4zU/MvMf04Fs51+y2p/rS1WZpRzN/qdfrWdv3oFXXm3nxjbvMXHsE3377pt8vMLcdXbjfzOlE5VfsQMU7hySZ54bO86vqMgBBX2xoUwZGRPHBM/yInGL5iZxi+YmcYvmJnGL5iZxi+YmcOmlu3R1mYKtWZv7eHVPN/PCPjgZmE6sGmNsuq+pl5i2+s9PM31scfFksAEz4XqMnVwIAFm7va27bfrJ92Wun/1lt5vtH25fVTvmPyYFZ2N8JZReP/EROsfxETrH8RE6x/EROsfxETrH8RE6x/EROhV7Pn0lRXs8fZ4MeDr4tOAB0mvrnrO277tuDzHz3j+2lrFdfMMPMW0lBU4dEaWjK9fw88hM5xfITOcXyEznF8hM5xfITOcXyEznF8hM55eZ6/jhb+S+/NvNZdwXf+x4A5u4Jnqvv1tpeNX1qyW/NPBzn8ZsrHvmJnGL5iZxi+YmcYvmJnGL5iZxi+YmcYvmJnAqd5xeRrgBmATgTQB2Aaao6WUQeAnArgMrEUyeoqr3gOjWqQPLM/JYzPg7JF2ZyOOREMif51AC4V1XXiEgbAKtF5LVE9riq/ip7wyOibAktv6ruBrA78fkBEdkIwD7ljIhir0nv+UWkO4BBAFYkHrpTRNaJyHQRaRewzXgRqRCRisrq2rQGS0SZk3T5RaQQwB8A3KOqnwF4EkAvAANR/5PBpMa2U9VpqlqmqmVFHez3tkSUO0mVX0QKUF/82ar6MgCo6h5VrVXVOgBPAyjP3jCJKNNCyy8iAuAZABtV9bEGjxc3eNo1AN7N/PCIKFuS+W3/xQBuBLBeRNYmHpsAYIyIDASgALYBuC0rIySirEjmt/3LADR2H3DO6RM1YzzDj8gplp/IKZafyCmWn8gplp/IKZafyCmWn8gplp/IKZafyCmWn8gplp/IKZafyCmWn8gplp/IKVHV3O1MpBLAhw0e6gigKmcDaJq4ji2u4wI4tlRlcmxnq2pRMk/MaflP2LlIhaqWRTYAQ1zHFtdxARxbqqIaG3/sJ3KK5SdyKuryT4t4/5a4ji2u4wI4tlRFMrZI3/MTUXSiPvITUUQiKb+IDBORzSLygYjcH8UYgojINhFZLyJrRaQi4rFMF5G9IvJug8fai8hrIvJ+4mOjy6RFNLaHROSjxGu3VkS+G9HYuorIGyKyUUQ2iMiPE49H+toZ44rkdcv5j/0ikgdgC4DLAOwEsArAGFV9L6cDCSAi2wCUqWrkc8IiMhjAQQCzVLV/4rFfAtinqhMT/3C2U9X7YjK2hwAcjHrl5sSCMsUNV5YGMBLAOET42hnjGo0IXrcojvzlAD5Q1a2qegTACwBGRDCO2FPVNwHsO+7hEQBmJj6fifpvnpwLGFssqOpuVV2T+PwAgGMrS0f62hnjikQU5S8BsKPBn3ciXkt+K4DFIrJaRMZHPZhGdE4sm35s+fROEY/neKErN+fScStLx+a1S2XF60yLovyNrf4TpymHi1X1fABXArgj8eMtJSeplZtzpZGVpWMh1RWvMy2K8u8E0LXBn7sA2BXBOBqlqrsSH/cCmIv4rT6859giqYmPeyMez1/FaeXmxlaWRgxeuziteB1F+VcB6C0iPUSkJYDrAcyPYBwnEJHWiV/EQERaA7gc8Vt9eD6AsYnPxwKYF+FYviIuKzcHrSyNiF+7uK14HclJPompjP8EkAdguqr+e84H0QgR6Yn6oz1Qv4jpc1GOTUSeBzAE9Vd97QHwIIBXAMwB0A3AdgDXqWrOf/EWMLYhqP/R9a8rNx97j53jsX0LwFIA6wHUJR6egPr315G9dsa4xiCC141n+BE5xTP8iJxi+YmcYvmJnGL5iZxi+YmcYvmJnGL5iZxi+Ymc+n951veKhP6C4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "%matplotlib inline  \n",
    "idx = randint(0, len(x_test))\n",
    "img = x_test[idx]\n",
    "plt.imshow(img.squeeze()) \n",
    "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "ind = (-pred).argsort()[:]\n",
    "latex = [class_names[x] for x in ind]\n",
    "print(latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('class_names.txt', 'w') as file_handler:\n",
    "    for item in class_names:\n",
    "        file_handler.write(\"{}\\n\".format(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
     ]
    }
   ],
   "source": [
    "model.save('keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflowjs in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (0.6.7)\n",
      "Requirement already satisfied: keras==2.2.2 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflowjs) (2.2.2)\n",
      "Requirement already satisfied: tensorflow-hub==0.1.1 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflowjs) (0.1.1)\n",
      "Requirement already satisfied: numpy==1.15.1 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflowjs) (1.15.1)\n",
      "Requirement already satisfied: h5py==2.8.0 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflowjs) (2.8.0)\n",
      "Requirement already satisfied: tensorflow==1.12.0 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflowjs) (1.12.0)\n",
      "Requirement already satisfied: six==1.11.0 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflowjs) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing==1.0.2 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from keras==2.2.2->tensorflowjs) (1.0.2)\n",
      "Requirement already satisfied: keras-applications==1.0.4 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from keras==2.2.2->tensorflowjs) (1.0.4)\n",
      "Requirement already satisfied: pyyaml in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflow-hub==0.1.1->tensorflowjs) (3.6.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflow==1.12.0->tensorflowjs) (0.6.1)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflow==1.12.0->tensorflowjs) (1.12.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflow==1.12.0->tensorflowjs) (1.14.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflow==1.12.0->tensorflowjs) (0.32.2)\n",
      "Requirement already satisfied: gast>=0.2.0 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflow==1.12.0->tensorflowjs) (0.2.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow-hub==0.1.1->tensorflowjs) (40.6.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/wangyimeng/anaconda3/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflowjs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\r\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format keras keras.h5 model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
